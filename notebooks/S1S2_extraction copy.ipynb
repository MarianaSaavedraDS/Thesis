{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWpzc8nY_X-I"
   },
   "source": [
    "# Input Files and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\Mariana Saavedra\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\python311.zip', 'C:\\\\Users\\\\Mariana Saavedra\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\DLLs', 'C:\\\\Users\\\\Mariana Saavedra\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib', 'C:\\\\Users\\\\Mariana Saavedra\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311', 'c:\\\\Users\\\\Mariana Saavedra\\\\Desktop\\\\Tese\\\\.venv', '', 'c:\\\\Users\\\\Mariana Saavedra\\\\Desktop\\\\Tese\\\\.venv\\\\Lib\\\\site-packages', 'c:\\\\users\\\\mariana saavedra\\\\desktop\\\\tese', 'c:\\\\Users\\\\Mariana Saavedra\\\\Desktop\\\\Tese\\\\.venv\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\Mariana Saavedra\\\\Desktop\\\\Tese\\\\.venv\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\Mariana Saavedra\\\\Desktop\\\\Tese\\\\.venv\\\\Lib\\\\site-packages\\\\Pythonwin']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YtvITnX1E3aX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1S2\n",
      "                                                   0  \\\n",
      "0  [(0.0, 0.04), (18.42, 18.52), (20.06, 20.16), ...   \n",
      "1  [(0.0, 0.04), (18.42, 18.52), (20.06, 20.16), ...   \n",
      "2  [(0.88, 1.0), (2.22, 2.2600000000000002), (4.9...   \n",
      "3  [(0.88, 1.0), (2.22, 2.2600000000000002), (4.9...   \n",
      "4  [(0.0, 0.06), (5.7, 5.84), (12.86, 12.98), (21...   \n",
      "\n",
      "                                                   2  \\\n",
      "0  [(17.54, 17.64), (19.7, 19.72), (20.3, 20.32),...   \n",
      "1  [(17.54, 17.64), (19.7, 19.72), (20.3, 20.32),...   \n",
      "2  [(0.0, 0.06), (1.2, 1.26), (3.9, 3.9), (19.44,...   \n",
      "3  [(0.0, 0.06), (1.2, 1.26), (3.9, 3.9), (19.44,...   \n",
      "4  [(2.8000000000000003, 2.86), (5.96, 6.04), (20...   \n",
      "\n",
      "                               Intervals_start_times  \\\n",
      "0  [17.54, 1.2799999999999976, 0.240000000000002,...   \n",
      "1  [17.54, 1.2799999999999976, 0.240000000000002,...   \n",
      "2  [0.31999999999999995, 1.6799999999999997, 14.4...   \n",
      "3  [0.31999999999999995, 1.6799999999999997, 14.4...   \n",
      "4  [2.8000000000000003, 0.2599999999999998, 7.5, ...   \n",
      "\n",
      "                                 Intervals_mid_times  \\\n",
      "0  [17.57, 1.240000000000002, 0.20000000000000284...   \n",
      "1  [17.57, 1.240000000000002, 0.20000000000000284...   \n",
      "2  [0.29000000000000004, 1.6599999999999997, 13.5...   \n",
      "3  [0.29000000000000004, 1.6599999999999997, 13.5...   \n",
      "4  [2.8000000000000003, 0.23000000000000043, 7.47...   \n",
      "\n",
      "                                 Intervals_end_times  \\\n",
      "0  [17.5, 1.1799999999999997, 0.14000000000000057...   \n",
      "1  [17.5, 1.1799999999999997, 0.14000000000000057...   \n",
      "2  [0.19999999999999996, 1.6399999999999997, 12.4...   \n",
      "3  [0.19999999999999996, 1.6399999999999997, 12.4...   \n",
      "4  [2.74, 0.1200000000000001, 7.379999999999999, ...   \n",
      "\n",
      "                            Filtered_intervals_start  \\\n",
      "0  [0.240000000000002, 0.22000000000000242, 0.239...   \n",
      "1  [0.240000000000002, 0.22000000000000242, 0.239...   \n",
      "2  [0.31999999999999995, 0.3399999999999963, 0.40...   \n",
      "3  [0.31999999999999995, 0.3399999999999963, 0.40...   \n",
      "4  [0.2599999999999998, 0.26000000000000156, 0.25...   \n",
      "\n",
      "                              Filtered_intervals_mid  \\\n",
      "0  [0.20000000000000284, 0.17999999999999972, 0.2...   \n",
      "1  [0.20000000000000284, 0.17999999999999972, 0.2...   \n",
      "2  [0.29000000000000004, 0.269999999999996, 0.350...   \n",
      "3  [0.29000000000000004, 0.269999999999996, 0.350...   \n",
      "4  [0.23000000000000043, 0.240000000000002, 0.209...   \n",
      "\n",
      "                              Filtered_intervals_end  Avg_intervals_start  \\\n",
      "0                                                 []             0.232000   \n",
      "1                                                 []             0.232000   \n",
      "2  [0.19999999999999996, 0.20000000000000284, 0.1...             0.353333   \n",
      "3  [0.19999999999999996, 0.20000000000000284, 0.1...             0.353333   \n",
      "4  [0.1799999999999926, 0.18000000000000682, 0.15...             0.268000   \n",
      "\n",
      "   Avg_intervals_mid  Avg_intervals_end   ID Auscultation Point  Status_of_EF  \\\n",
      "0           0.194000                NaN  1.0                 PV             2   \n",
      "1           0.194000                NaN  1.0                 TV             2   \n",
      "2           0.303333              0.215  1.0                 PV             2   \n",
      "3           0.303333              0.215  1.0                 TV             2   \n",
      "4           0.223000              0.175  1.0                 PV             2   \n",
      "\n",
      "   HR (Heart rate)   S1S2  \n",
      "0        66.489362  343.7  \n",
      "1        65.005417  345.3  \n",
      "2        66.489362  343.7  \n",
      "3        65.005417  345.3  \n",
      "4        66.489362  343.7  \n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# # Imports\n",
    "\n",
    "# Standard libraries\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Numerical and data processing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# TensorFlow and Keras\n",
    "from tensorflow import keras\n",
    "\n",
    "# Custom libraries\n",
    "from libs.paths import data_folder, results_folder, models_folder\n",
    "from libs import feature_extraction_lib as ftelib\n",
    "from libs.feature_extraction_lib_extension import process_pcg_signals_from_pkl\n",
    "from libs.label_mappings import get_label_meaning\n",
    "\n",
    "from libs import unet_model as unet\n",
    "\n",
    "# # Input files\n",
    "\n",
    "signal = 'pcg'\n",
    "label_x = 0  # Replace with your chosen label for x\n",
    "label_y = 2  # Replace with your chosen label for y\n",
    "\n",
    "label_string = get_label_meaning(signal, label_x, label_y)\n",
    "\n",
    "print(label_string)  # Output: 'S1S2' for PCG, 'baseline segmento QRS' for ECG\n",
    "\n",
    "# Load Estimates\n",
    "data_file_path = results_folder / f\"{label_string}_estimates_and_annotations.csv\"\n",
    "df = pd.read_csv(data_file_path)  # Use read_csv instead of read_pickle for CSV files\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 828,
     "status": "ok",
     "timestamp": 1738449149773,
     "user": {
      "displayName": "Mariana Louren√ßo",
      "userId": "17945093930787008575"
     },
     "user_tz": 0
    },
    "id": "XCdD3V6xF43F",
    "outputId": "b457ee37-bcd5-42ea-e26f-87d9c45f58a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[array([[0.35381019, 0.2540606 , 0.19457965, 0.19754964],\n",
      "       [0.38906765, 0.17533119, 0.26615313, 0.16944799],\n",
      "       [0.35643852, 0.18448004, 0.28323871, 0.17584267],\n",
      "       ...,\n",
      "       [0.29280463, 0.16435444, 0.19531116, 0.34752983],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ]]), array([[0.01414598, 0.05432292, 0.01166636, 0.91986471],\n",
      "       [0.0070835 , 0.0327984 , 0.00253604, 0.957582  ],\n",
      "       [0.00808579, 0.04174281, 0.00207181, 0.94809949],\n",
      "       ...,\n",
      "       [0.05297251, 0.09965677, 0.59228003, 0.25509074],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ]]), array([[0.00636502, 0.01882447, 0.03067411, 0.9441365 ],\n",
      "       [0.00358492, 0.00824108, 0.01072847, 0.97744554],\n",
      "       [0.0043205 , 0.00770316, 0.00896073, 0.97901553],\n",
      "       ...,\n",
      "       [0.00194044, 0.00789562, 0.00138208, 0.98878181],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ]]), array([[0.04696094, 0.1739493 , 0.10874853, 0.67034113],\n",
      "       [0.03495467, 0.11108293, 0.10066991, 0.7532925 ],\n",
      "       [0.04127661, 0.10011622, 0.12204687, 0.73656034],\n",
      "       ...,\n",
      "       [0.13892367, 0.11506876, 0.07920174, 0.6668058 ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ]]), array([[0.00658698, 0.03870419, 0.00831147, 0.9463973 ],\n",
      "       [0.00295043, 0.02105889, 0.00202358, 0.97396702],\n",
      "       [0.00353196, 0.02329171, 0.00155779, 0.97161859],\n",
      "       ...,\n",
      "       [0.07083196, 0.0996189 , 0.17258283, 0.65696639],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ]])]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Define the path where the file is stored\n",
    "predictions_pickle_path = '/content/drive/MyDrive/Tese/Daniel_PCG_UNET/Resultados Mariana/reconstructed_labels.pkl'\n",
    "\n",
    "# Load the pickle file\n",
    "with open(predictions_pickle_path, 'rb') as file:\n",
    "    predictions = pickle.load(file)\n",
    "\n",
    "# Print or check the loaded data\n",
    "print(type(predictions))  # Check the type of loaded object\n",
    "print(predictions[:5])  # Print the first few elements (if it's a list or array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Qoxv_ylD2dX"
   },
   "source": [
    "#Automatic S1S2 extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1738449149773,
     "user": {
      "displayName": "Mariana Louren√ßo",
      "userId": "17945093930787008575"
     },
     "user_tz": 0
    },
    "id": "xzN6qSjyHi-4",
    "outputId": "d0f9383b-80d3-4d77-8f29-28000a2285f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.22645219, 0.32340893, 0.36696267, ..., 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_probabilities = pd.DataFrame({\n",
    "    'S1': [signal[:, 0] for signal in predictions],\n",
    "    'S2': [signal[:, 2] for signal in predictions]\n",
    "})\n",
    "\n",
    "# Access S1 probabilities for signal 5\n",
    "df_probabilities.iloc[5]['S1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S60b-frcl8b0"
   },
   "source": [
    "## Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1738449149774,
     "user": {
      "displayName": "Mariana Louren√ßo",
      "userId": "17945093930787008575"
     },
     "user_tz": 0
    },
    "id": "dssZe8DuyZ8A",
    "outputId": "88e27f65-0b5f-47d2-d786-63080d34d3b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  S1  \\\n",
      "0  [0.35381019115448, 0.3890676498413086, 0.35643...   \n",
      "1  [0.014145980589091778, 0.007083502132445574, 0...   \n",
      "2  [0.0063650161027908325, 0.0035849222913384438,...   \n",
      "3  [0.04696093872189522, 0.03495466709136963, 0.0...   \n",
      "4  [0.006586980074644089, 0.002950427122414112, 0...   \n",
      "\n",
      "                                                  S2  \\\n",
      "0  [0.19457964599132538, 0.26615312695503235, 0.2...   \n",
      "1  [0.011666355654597282, 0.0025360428262501955, ...   \n",
      "2  [0.03067411296069622, 0.010728465393185616, 0....   \n",
      "3  [0.10874853283166885, 0.10066991299390793, 0.1...   \n",
      "4  [0.008311466313898563, 0.0020235825795680285, ...   \n",
      "\n",
      "                                         S1_filtered  \\\n",
      "0  [0.3448824810981751, 0.3245721089839935, 0.289...   \n",
      "1  [0.012434091232717038, 0.02084208713844419, 0....   \n",
      "2  [0.005318782636895776, 0.0047213813662529, 0.0...   \n",
      "3  [0.044060727208852776, 0.042983179837465295, 0...   \n",
      "4  [0.005383932376280428, 0.005270281061530114, 0...   \n",
      "\n",
      "                                         S2_filtered  \n",
      "0  [0.22238786339759828, 0.23297985017299652, 0.2...  \n",
      "1  [0.007913422090932728, 0.006390781868249178, 0...  \n",
      "2  [0.02195856225676835, 0.017137248790822925, 0....  \n",
      "3  [0.11370241403579714, 0.11827383488416673, 0.1...  \n",
      "4  [0.0056852562446147205, 0.004371583554893733, ...  \n"
     ]
    }
   ],
   "source": [
    "# Define the function for processing S1 and S2 columns\n",
    "def apply_moving_average(df, window_size):\n",
    "    \"\"\"\n",
    "    Apply the moving average filter to S1 and S2 probabilities in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Input DataFrame containing S1 and S2 columns with probabilities as lists/arrays.\n",
    "    window_size : int\n",
    "        The size of the moving average window.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Updated DataFrame with filtered S1 and S2 probabilities.\n",
    "    \"\"\"\n",
    "    df['S1_filtered'] = df['S1'].apply(lambda x: pplib.moving_average(np.array(x), window_size))\n",
    "    df['S2_filtered'] = df['S2'].apply(lambda x: pplib.moving_average(np.array(x), window_size))\n",
    "    return df\n",
    "\n",
    "# Apply the function to your DataFrame\n",
    "window_size = 5  # Adjust this as needed (must be a positive odd integer)\n",
    "df_probabilities = apply_moving_average(df_probabilities, window_size)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df_probabilities.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Co8akNTr1Syb"
   },
   "source": [
    "## First Approach: peak of the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1738449149774,
     "user": {
      "displayName": "Mariana Louren√ßo",
      "userId": "17945093930787008575"
     },
     "user_tz": 0
    },
    "id": "R0H62ayV0zY1",
    "outputId": "5f99c234-2488-40e6-fe7c-361f3ef46e71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        S1_positions  \\\n",
      "0  [110, 141, 359, 761, 788, 851, 896, 940, 1060,...   \n",
      "1  [9, 46, 91, 121, 228, 278, 322, 463, 511, 575,...   \n",
      "2  [20, 66, 110, 156, 201, 247, 308, 337, 380, 42...   \n",
      "3  [23, 100, 128, 203, 245, 404, 493, 569, 649, 6...   \n",
      "4  [10, 40, 68, 98, 128, 157, 186, 218, 247, 373,...   \n",
      "\n",
      "                                        S2_positions  \\\n",
      "0                                             [1431]   \n",
      "1  [24, 61, 134, 294, 893, 1077, 1124, 1306, 1352...   \n",
      "2  [37, 82, 173, 218, 263, 352, 397, 442, 532, 57...   \n",
      "3       [663, 818, 864, 894, 1057, 1186, 1216, 1287]   \n",
      "4  [22, 51, 80, 110, 139, 168, 198, 230, 260, 385...   \n",
      "\n",
      "                                      S1S2_intervals  \n",
      "0  [1321, 1290, 1072, 670, 643, 580, 535, 491, 37...  \n",
      "1  [15, 15, 43, 13, 66, 16, 571, 430, 382, 318, 1...  \n",
      "2  [17, 16, 63, 17, 17, 16, 44, 15, 17, 17, 61, 1...  \n",
      "3  [640, 563, 535, 460, 418, 259, 170, 94, 14, 13...  \n",
      "4  [12, 11, 12, 12, 11, 11, 12, 12, 13, 12, 12, 1...  \n"
     ]
    }
   ],
   "source": [
    "from scipy.signal import find_peaks\n",
    "\n",
    "def extract_positions(probabilities, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Extract positions of peaks above the threshold for a given probability array.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    probabilities : numpy.ndarray\n",
    "        Filtered probability array (e.g., S1 or S2 probabilities).\n",
    "    threshold : float\n",
    "        Threshold value to consider a point as a peak.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    list\n",
    "        Positions of detected peaks above the threshold.\n",
    "    \"\"\"\n",
    "    # Find peaks in the probability array\n",
    "    peaks, _ = find_peaks(probabilities, height=threshold)\n",
    "    return peaks.tolist()\n",
    "\n",
    "# Apply the function to S1 and S2 filtered probabilities\n",
    "df_probabilities['S1_positions'] = df_probabilities['S1_filtered'].apply(\n",
    "    lambda x: extract_positions(x, threshold=0.5)\n",
    ")\n",
    "\n",
    "df_probabilities['S2_positions'] = df_probabilities['S2_filtered'].apply(\n",
    "    lambda x: extract_positions(x, threshold=0.5)\n",
    ")\n",
    "\n",
    "# Example of S1-S2 interval calculation\n",
    "def calculate_s1s2_intervals(row):\n",
    "    \"\"\"\n",
    "    Calculate the intervals between S1 and S2 peaks.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    row : pandas.Series\n",
    "        A row of the DataFrame containing S1_positions and S2_positions.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    list\n",
    "        S1-S2 intervals for the current signal.\n",
    "    \"\"\"\n",
    "    s1_positions = row['S1_positions']\n",
    "    s2_positions = row['S2_positions']\n",
    "    intervals = []\n",
    "    for s1 in s1_positions:\n",
    "        # Find the closest S2 that occurs after the current S1\n",
    "        s2_after = [s2 for s2 in s2_positions if s2 > s1]\n",
    "        if s2_after:\n",
    "            intervals.append(s2_after[0] - s1)\n",
    "    return intervals\n",
    "\n",
    "# Apply interval calculation to the DataFrame\n",
    "df_probabilities['S1S2_intervals'] = df_probabilities.apply(calculate_s1s2_intervals, axis=1)\n",
    "\n",
    "# Display the DataFrame with extracted positions and intervals\n",
    "print(df_probabilities[['S1_positions', 'S2_positions', 'S1S2_intervals']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1738449149774,
     "user": {
      "displayName": "Mariana Louren√ßo",
      "userId": "17945093930787008575"
     },
     "user_tz": 0
    },
    "id": "EBDTWEbe2CzQ",
    "outputId": "9b45fda8-66a7-40b0-c6e4-6939c255af47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        S1_positions  \\\n",
      "0  [110, 141, 359, 761, 788, 851, 896, 940, 1060,...   \n",
      "1  [9, 46, 91, 121, 228, 278, 322, 463, 511, 575,...   \n",
      "2  [20, 66, 110, 156, 201, 247, 308, 337, 380, 42...   \n",
      "3  [23, 100, 128, 203, 245, 404, 493, 569, 649, 6...   \n",
      "4  [10, 40, 68, 98, 128, 157, 186, 218, 247, 373,...   \n",
      "\n",
      "                                        S2_positions  \\\n",
      "0                                             [1431]   \n",
      "1  [24, 61, 134, 294, 893, 1077, 1124, 1306, 1352...   \n",
      "2  [37, 82, 173, 218, 263, 352, 397, 442, 532, 57...   \n",
      "3       [663, 818, 864, 894, 1057, 1186, 1216, 1287]   \n",
      "4  [22, 51, 80, 110, 139, 168, 198, 230, 260, 385...   \n",
      "\n",
      "                                      S1S2_intervals  \n",
      "0                                               [12]  \n",
      "1           [15, 15, 13, 16, 17, 17, 18, 15, 16, 14]  \n",
      "2  [17, 16, 17, 17, 16, 15, 17, 17, 17, 17, 17, 1...  \n",
      "3                       [14, 14, 15, 13, 17, 13, 11]  \n",
      "4  [12, 11, 12, 12, 11, 11, 12, 12, 13, 12, 12, 1...  \n"
     ]
    }
   ],
   "source": [
    "def calculate_s1s2_intervals(row, min_interval, max_interval):\n",
    "    \"\"\"\n",
    "    Calculate the intervals between S1 and S2 peaks, with restrictions on valid ranges.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    row : pandas.Series\n",
    "        A row of the DataFrame containing S1_positions and S2_positions.\n",
    "    min_interval : int\n",
    "        Minimum acceptable interval in samples.\n",
    "    max_interval : int\n",
    "        Maximum acceptable interval in samples.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    list\n",
    "        Valid S1-S2 intervals for the current signal.\n",
    "    \"\"\"\n",
    "    s1_positions = row['S1_positions']\n",
    "    s2_positions = row['S2_positions']\n",
    "    intervals = []\n",
    "\n",
    "    # Ensure there are both S1 and S2 peaks\n",
    "    if not s1_positions or not s2_positions:\n",
    "        return intervals  # Return empty if no valid peaks\n",
    "\n",
    "    for s1 in s1_positions:\n",
    "        # Find the closest S2 that occurs after the current S1\n",
    "        s2_after = [s2 for s2 in s2_positions if s2 > s1]\n",
    "        if s2_after:\n",
    "            interval = s2_after[0] - s1\n",
    "            # Add interval if it is within the acceptable range\n",
    "            if min_interval <= interval <= max_interval:\n",
    "                intervals.append(interval)\n",
    "    return intervals\n",
    "\n",
    "# Sampling frequency (Hz) and interval range (ms to samples)\n",
    "fs = 50  # Sampling frequency\n",
    "min_interval = int(200 * fs / 1000)  # Convert 200 ms to samples\n",
    "max_interval = int(500 * fs / 1000)  # Convert 500 ms to samples\n",
    "\n",
    "# Apply the function to calculate valid S1-S2 intervals\n",
    "df_probabilities['S1S2_intervals'] = df_probabilities.apply(\n",
    "    calculate_s1s2_intervals,\n",
    "    axis=1,\n",
    "    min_interval=min_interval,\n",
    "    max_interval=max_interval\n",
    ")\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df_probabilities[['S1_positions', 'S2_positions', 'S1S2_intervals']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1738449149774,
     "user": {
      "displayName": "Mariana Louren√ßo",
      "userId": "17945093930787008575"
     },
     "user_tz": 0
    },
    "id": "thBariSS3a12",
    "outputId": "b098ce56-7b59-4f7b-cafe-98f1b11c5e03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      S1S2_intervals  Avg_S1S2_interval_ms\n",
      "0                                               [12]            240.000000\n",
      "1           [15, 15, 13, 16, 17, 17, 18, 15, 16, 14]            312.000000\n",
      "2  [17, 16, 17, 17, 16, 15, 17, 17, 17, 17, 17, 1...            334.666667\n",
      "3                       [14, 14, 15, 13, 17, 13, 11]            277.142857\n",
      "4  [12, 11, 12, 12, 11, 11, 12, 12, 13, 12, 12, 1...            235.200000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define a function to convert intervals to time and calculate the average\n",
    "def calculate_avg_interval(row, fs):\n",
    "    \"\"\"\n",
    "    Convert S1S2 intervals to time (ms) and calculate the average.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    row : pandas.Series\n",
    "        A row of the DataFrame containing S1S2 intervals.\n",
    "    fs : int\n",
    "        Sampling frequency in Hz.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    float\n",
    "        Average S1S2 interval in milliseconds, or NaN if no intervals exist.\n",
    "    \"\"\"\n",
    "    intervals = row['S1S2_intervals']\n",
    "    if intervals:  # Ensure there are valid intervals\n",
    "        intervals_ms = [interval * 1000 / fs for interval in intervals]\n",
    "        return np.mean(intervals_ms)  # Calculate and return the average in ms\n",
    "    else:\n",
    "        return np.nan  # Return NaN for signals with no intervals\n",
    "\n",
    "# Apply the function to calculate the average S1S2 interval in ms\n",
    "df_probabilities['Avg_S1S2_interval_ms'] = df_probabilities.apply(\n",
    "    calculate_avg_interval, axis=1, fs=fs\n",
    ")\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df_probabilities[['S1S2_intervals', 'Avg_S1S2_interval_ms']].head())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "YWpzc8nY_X-I",
    "S60b-frcl8b0",
    "Co8akNTr1Syb"
   ],
   "provenance": [
    {
     "file_id": "14-JEBvMnZ2mBh3rsWcjcKI5htsNoo5zX",
     "timestamp": 1738152064218
    },
    {
     "file_id": "1GkcWPkCf4xHQxP8QbmBAAlwSFd6C01ql",
     "timestamp": 1737892456648
    }
   ]
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
